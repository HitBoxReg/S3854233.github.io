<!DOCTYPE html>
<html>
    <head>
        <title>Assignment 1</title>
        <meta name="description" content="Assignment 1 Personal website">
        <meta name="keywords" content="Project Idea">
        <style type="text/css">
            #main-header
            {
                text-align:center;
                background-color: black;
                color:rgb(255, 255, 255);
                padding:10px;
                margin: 0px;
                border: 5px grey solid;
                border-radius: 20px;
                opacity: 0.8;
                text-shadow: 2px 2px rgb(148, 134, 87);
            }
            #main-footer
            {
                text-align:center;
                font-size: 18px;
            }
            body
            {
                background-image: url('images/Background.png');
                font-family: Arial, Helvetica, sans-serif;
            }
            h2
            {
                background-color: black;
                color: white;
                border: 5px grey solid;
                border-radius: 20px;
                padding: 5px;
                text-align: left;
                margin-right: 1200px;
                text-align: center;
            }
            p
            {
                color: rgb(12, 82, 53);
                border: 5px white dotted;
                margin-left: 20px;
                margin-right: 20px;
                padding: 10px;
                font-size: 18px;
                font-style: italic;
                background-color: rgb(252, 247, 201);
                opacity: 0.9;
            }
            ul
            {
                color: rgb(12, 82, 53);
                border: 5px white dotted;
                margin-left: 20px;
                margin-right: 20px;
                padding: 10px;
                font-size: 18px;
                background-color: rgb(252, 247, 201);
                opacity: 0.9;
            }
            ol
            {
                color: rgb(12, 82, 53);
                font-size: 18px;
                text-align: center;
                list-style-position: inside;
                background-color: rgb(252, 247, 201);
                opacity: 0.9;
                border: 5px white dotted;
                margin-left: 200px;
                margin-right: 200px;
                padding: 10px;
                border-radius: 50px;
            }
            .image
            {
                display: block;
                margin-left: auto;
                margin-right: auto;
            }
        </style>
    </head>
    <body>
        <header id="main-header">
            <h1>Personal Website</h1>
        </header>

        <h2>PERSONAL INFO</h2>
        <ul>
            <li>Name: Hoang Minh Khoi</li>
            <li>Student ID: s3854233</li>
            <li>Email: s3854233@rmit.edu.vn</li>
            <li>Background: Vietnamese, atheist, fluent in English and Vietnamese. </li>
            <li>I’m not that interesting a person, unless having a pretty dumb pet cat is considered interesting.
                I am also somewhat of an audiophile, which just means I listen to music in an unhealthy amount with an unhealthy obsession for sound quality and audio peripherals.</li>
            <li><img src="images/pic.jpg" alt="Picture of self"></li>
        </ul>
        <h2>INTEREST IN IT</h2>
        <p>
            There isn’t much to say about my interest in IT as a whole, I love to code, regardless of the different branches and departments. 
            The process of writing, debugging, and solving problems is an extremely gratifying experience for me. 
            I started my love for computers when I was around 4th grade, around the time my father purchased our first desktop pc. 
            I strictly stuck to using it for video games and entertainment for a very long time and only ever wrote simple scripts for game mods that I installed. 
            I decided to come RMIT because my prior experience with public institutions did not provide me with any useful knowledge for my field of passion (IT) –
             I spent a year at a public university in Thu Duc and the experience was miserable. 
            In just a few weeks I learned more useful and practical knowledge than I did the previous year and I am certain there is only more to come.
        </p>
        <h2>IDEAL JOB</h2>
        <br>
        <a href="images/Job.png">
            <img src="images/Job.png" alt="Ideal Job Screenshot" class="image">
        </a>
        <br>
        <p>
            Data analytics is the science of examining raw data, applying an algorithmic or mechanical process to derive insights or look for meaningful correlations between each other. 
            This field requires you to find patterns in seemingly unrelated data sets and is one of the keys in creating AI algorithms – what I believe to be the future of IT.
        </p>
        <p>
            Data analysts build and improve machine learning models, create data solutions whilst also monitoring and analyzing operational data. 
            The end goal is to improve upon the efficiency of the data solutions/models that were created. 
            Because of the difficulty and fledgling nature of this field, descriptive and inferential statistics and experimental designs are a must, as well as data wrangling skills – the ability to map raw data and convert it into another format that allows for more convenient consumption of the data, knowledge of programming languages like R and Python is also extremely important.
        </p>
        <p>
            The most difficult part in acquiring the aforementioned qualifications for me will be learning the mathematical and statistical knowledge and its applications in the field. 
            The programming languages can be learned like any other programming language – with the help of the internet. 
            This means during university I am to major in data analytics or something of resemblance and take all the electives that coin spire with data science.
        </p>
        <h2>PERSONAL PROFILE</h2>
        <ol>
            <li>Myers-Briggs test:</li>
            <br>
            <a href="images/MB.png">
                <img src="images/MB.png" alt="MB test" class="image">
            </a>
            <br>
            <li>Learning style test:</li>
            <br>
            <a href="images/LS.png">
                <img src="images/LS.png" alt="Learning style" class="image">
            </a>
            <br>
            <li>Perceptual test:</li>
            <br>
            <a href="images/Perceptual.png">
                <img src="images/Perceptual.png" alt="Perceptual test" class="image">
            </a>
            <br>
        </ol>
        <p>
            The result of Myers-Briggs test gave me an insight into what sort of teammate I am and how I could improve upon my interactions with future group members. 
            The learning style test seems the most inconclusive as I am only marginally better as an auditory learner than I am a Visual one according to the results. 
            The perceptual skills test was a surprise as I had not expected to perform as well as I did, there were multiple questions that I struggled on so there may have been some element of luck involved.
        </p>
        <p>
            Perhaps the biggest takeaway for me is how the Myers-Briggs test seem to indicate a permissive nature in my behavior that may annoy coworkers and the like. 
            To alleviate this, whenever I am apart of a team, I must put more forethought into my actions and words to refrain from over-stepping boundaries.
        </p>
        <br>
        <h2>PROJECT IDEA</h2>
        <br>
        <p>
            We are no strangers to using machine leaning in order to better our means of communication – Google’s speech to text API, the abundance of voice recognition software, voice translation applications. 
            Now more than ever, the language barrier has become increasingly thin with the help of AIs. 
            Taking that same concept of using machines to aid us in understanding one another more efficiently, why not apply those same tools to further our understanding of animals? 
            Animal communication has come a long way, but most, if not all progress in this field require vast amounts of time to gather, process, and decode the signals used by animals to communicate – 
            from visual, auditory, chemical (pheromones), to tactile (touch-based), things not unlike the data used to analyze our own methods of communication (body language, facial expressions, tone of voice, etc..). 
            A more relatable aspect of using AI to study animal communication would be a mobile app capable of translating the audio cues, and perhaps even the body language (with the use of smartphone cameras), of the most common household pets - from dogs, to cats and birds.
        </p>
        <p>
            There are over 400 million dogs that are kept as pets worldwide with the second most popular animal companion being cats at over 300 million in 2018 (Bedford, 2020). 
            Most of our daily interactions with household pets is based on conjecture and previous studies of animal behavior with a majority of pet owners either having limited or basic knowledge of how and what their pets want to communicate. 
            The most difficult part of communicating with animals arises in animal-care, when your pet is sick or in distress and vice versa. 
            The use of AI technology can greatly improve our ability to detect when pets are in emotional or physical discomfort, and the accessibility of a mobile app makes it the platform of choice to develop this tool.
        </p>
        <p>
            On first launch after installation, the user is prompted to allow camera, microphone and storage permissions. 
            The target demographic for this application is for anyone with a household pet and this includes children, so the graphical interface will have to be child friendly whilst also having a high level of ease of use. 
            The main feature of the application will be translating a recording of the pet using the mobile device like a speech-to-text API for animal sounds by cross-checking the audio on a database with cloud technology. 
            Another feature will be to analyze footage of an animal (body language) that was uploaded on to the cloud to determine what emotion the animal is displaying and will first prompt the user to categorize what animal, and its specific breed, is in the footage they will upload(dog, cat, bird, etc...). 
            The user is to then film the associated animal’s key characteristics with instructions from the app, like the tail behavior and ear positions of the dog or cat, pupil dilation, wing positions, etc.… (This can be done with current facial recognition technology). 
            After receiving all the required data (footage, pictures, audio files), it will provide a possible synopsis of what the animal is feeling (happy, scared, angry, hungry, etc.) as on-screen text whilst also providing tips on how to navigate the situation. 
            For offline use (lack of access to an internet connection), there is a handbook feature with graphical illustrations and useful information to help determine what possible emotions their pets are exhibiting – are the ears pointed forward or slumped? 
            Is the tail cupped downwards or upwards? Are the feathers spread outwards? etc. 
            As the product uses personal video footage and audio, there must be proper security measures implemented – 
            encryption of all user data and data held on the cloud, a user login feature. 
            Moreover, audio and video footage sent by the user must be kept for reference in the data set of the system to improve the accuracy and efficiency of the product, which is the standard practice in most apps on the market and is stated clearly in the Terms and Conditions (Flora, Wang & Chande 2014, p. 1).
        </p>
        <p>
            The product will use cloud technology, and with no shortage of providers there is a multitude of very secure options – Microsoft Azure, Amazon Web Services, Google Cloud, Oracle… 
            This will become the data set for an in-house AI algorithm, built with the help of The Earth Species Project – currently in the development as an open source project that will provide a toolkit, data sets, benchmarks, and community for unsupervised translation that incorporates a focus on non-human languages with state-of-the-art academic research, 
            and current facial recognition technology but applied for animals, as well as for storage (to alleviate the loss of storage capacity for the user).
        </p>
        <p>
            The most important part of the product will be the AI to be written and developed, which has to solve two difficult problems in animal communication: The Umwelt Problem, The Carrier-Signal and Cocktail Party Problems. 
            The Earth Species Project is currently implementing machine learning to solve these issues, but the use of AI in this field is relatively new to us and thus, insufficient progress and understanding will cause the creation of the aforementioned in-house AI to be a very difficult task, 
            this coupled with the fact that the finish line for The Earth Species Project is still to-be-determined does not improve the likelihood of a successful development. 
            However, it is only a matter of time until machine learning in communication progresses far enough for such an algorithm to be feasible. 
            There is also virtually no limitation on the hardware-level with our advances in mobile devices.
        </p>
        <p>
            Success of the project will be a massive push for both animal communication and machine learning by not only giving us a commercially available tool that aids animal-care, but further our understanding of inter-species communication – to understand the neighbors we share this world with, and progress AI development in language translation (which we’ve become very efficient at) that goes beyond human languages. 
            Being able to understand animals does more than help forge closer emotional ties with them. 
            It could remove the deduction and conjecture required in helping animals in farms and homeless situations – 625 thousand animals in shelters were killed in 2019 in the US (Best Friends 2019), like detecting pain and sickness in farm animals. 
            The end result will improve the lives of all living species we interact with and in turn, our lives as well as we all share an ecosystem.
        </p>
        <footer id="main-footer">
            <p>Copyright &copy; 2020, S3854233</p>
        </footer>
    </body>
</html>
